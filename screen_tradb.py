#!/usr/bin/env python

import argparse
import pandas as pd
import os
import re
import sqlite3


version_number = str("screen_tradb version 0.2")

home_dir = os.path.expanduser('~')


def run_platon(infile, basename, num_proc, platon_db_dir):
    """
    Run the Platon tool to predict plasmids from a given input file.

    Parameters:
    infile (str): Path to the input file to be processed by Platon.
    basename (str): Base name for the output files generated by Platon.
    num_proc (int): Number of processor threads to use for Platon.
    platon_db_dir (str): Directory path where the Platon database is stored.

    Description:
    This function constructs and executes a command to run Platon with specified parameters.
    If the Platon database directory does not exist, it downloads and extracts the database
    from a specified URL. The function then prints the constructed command and executes it
    using the os.system() method.

    Note:
    Ensure that the 'platon' tool is installed and accessible from the command line.
    """

    platon_cmd = f'platon --db {home_dir}/platon_db/db/ --output {basename}_platon --mode accuracy --threads {num_proc} {infile}'

    if not os.path.exists(platon_db_dir):
        wget_cmd = f'wget https://zenodo.org/record/4066768/files/db.tar.gz -O {home_dir}/platon_db.tar.gz'
        tar_cmd = f'mkdir {home_dir}/platon_db && tar -xzf {home_dir}/platon_db.tar.gz -C {home_dir}/platon_db'
        os.system(wget_cmd)
        os.system(tar_cmd)

    print(f'predicting plasmids with platon using the command: {platon_cmd}')
    os.system(platon_cmd)


def run_prodigal(infile, basename, outdir):
    """
    Run Prodigal to predict open reading frames (ORFs) and process the output.

    This function executes Prodigal to predict ORFs from a given input file, processes the resulting amino acid sequences
    to replace certain characters, and handles potential issues with Prodigal's DNA output by using bedtools as a workaround.

    Args:
        infile (str): Path to the input file containing nucleotide sequences.
        basename (str): Base name for the output files.
        outdir (str): Directory where the output files will be saved.

    Returns:
        None

    Outputs:
        - {basename}_aa.fa: Amino acid sequences predicted by Prodigal.
        - {basename}.gff: GFF file containing the ORF predictions.
        - {basename}.bed: BED file with corrected coordinates for the ORFs.
        - {basename}_dna.fa: DNA sequences corresponding to the predicted ORFs.
    """

    prodigal_cmd = f'prodigal -i {infile} -p meta -f gff -a {outdir}/{basename}_aa.fa -o {outdir}/{basename}.gff 2> /dev/null'
    os.system(prodigal_cmd)
    print("ORF prediction complete")

    # could parse as fasta but as the replaced characters must not appear in AA sequences this solution will do for now
    # TODO remove partial!
    pattern = r'>([\w\.]+)_(\d+) # (\d+) # (\d+).+'

    with open(f'{outdir}/{basename}_aa.fa', 'r') as file:
        amino_acids = file.read()
        amino_acids = re.sub(pattern, r'>\1:\3-\4', amino_acids)

    with open(f'{outdir}/{basename}_aa.fa', 'w') as file:
        file.write(amino_acids)

    # sometimes prodigal fails to output the DNA (no problem with AA), below there is a workaround to this rare problem
    filtered_lines = []
    with open(f'{outdir}/{basename}.gff', 'r') as gff_file:
        for line in gff_file:
            if not line.startswith("#") and "partial=01" not in line:
                fields = line.strip().split("\t")
                start = str(int(fields[3]) - 1)  # correct 1-based coordinates
                filtered_lines.append((fields[0], start, fields[4]))

    with open(f'{outdir}/{basename}.bed', 'w') as bed_file:
        for entry in filtered_lines:
            bed_file.write("\t".join(entry) + "\n")

    bedtools_cmd = f'bedtools getfasta -fi {infile} -bed {outdir}/{basename}.bed > {outdir}/{basename}_dna.fa'
    os.system(bedtools_cmd)


def filter_hits(raw_hits, filtered_hits, identity, coverage, evalue):
    """
    Filters BLAST hits based on identity, coverage, and e-value thresholds, and selects the best hit for each query.

    Parameters:
    raw_hits (str): Path to the input file containing raw BLAST hits in tab-separated format.
    filtered_hits (str): Path to the output file where filtered hits will be saved in tab-separated format.
    identity (float): Minimum percentage identity threshold for filtering hits.
    coverage (float): Minimum query coverage percentage threshold for filtering hits.
    evalue (float): Maximum e-value threshold for filtering hits.

    Returns:
    None
    """

    identity = float(identity)
    coverage = float(coverage)
    evalue = float(evalue)

    hits = pd.read_csv(raw_hits, sep='\t')

    hits['pident'] = pd.to_numeric(hits['pident'], errors='coerce')
    hits['qcov'] = pd.to_numeric(hits['qcov'], errors='coerce')
    hits['evalue'] = pd.to_numeric(hits['evalue'], errors='coerce')
    hits['bits'] = pd.to_numeric(hits['bits'], errors='coerce')

    hits = hits[(hits['pident'] >= identity) & 
                (hits['qcov'] >= coverage) & 
                (hits['evalue'] <= evalue)]

    filtered = hits.groupby('query', as_index=False).apply(lambda group: group.loc[group['bits'].idxmax()])

    filtered.rename(columns={'target': 'cluster'}, inplace=True)

    filtered.reset_index(drop=True, inplace=True)

    filtered.to_csv(filtered_hits, sep='\t', index=False)

    print(f'Filtered hits saved to {filtered_hits}')


# TODO frequency of reference taxa / gene
def get_metadata(filtered_hits, sqlite_db, hit_data):
    """
    This function reads a filtered hits file, retrieves metadata from a SQLite database,
    and merges the metadata with the hits data. The merged data is then saved to a specified file.

    Args:
        filtered_hits (str): Path to the filtered hits file in tab-separated format.
        sqlite_db (str): Path to the SQLite database file.
        hit_data (str): Path to the output file where merged data will be saved in tab-separated format.

    Returns:
        None

    The function performs the following steps:
        1. Reads the filtered hits file into a pandas DataFrame.
        2. Extracts unique clusters from the hits data.
        3. Constructs a SQL query to retrieve metadata (taxa and position) for the clusters from the SQLite database.
        4. Cleans the retrieved metadata by removing unwanted characters from 'taxa' and 'position' columns.
        5. Merges the hits data with the metadata on the 'cluster' column.
        6. Saves the merged data to the specified output file in tab-separated format.
        7. Prints a message indicating the location of the saved metadata.
    """

    hits = pd.read_csv(filtered_hits, sep='\t')

    #  hits.rename(columns={'target': 'cluster'}, inplace=True)

    clusters = hits['cluster'].unique()

    clusters_placeholder = ','.join([f"'{cluster}'" for cluster in clusters])

    conn = sqlite3.connect(sqlite_db)

    query = f"SELECT cluster, taxa, position FROM data WHERE cluster IN ({clusters_placeholder})"
    metadata = pd.read_sql_query(query, conn)

    conn.close()

    metadata['taxa'] = metadata['taxa'].str.replace(r"[\[\]']", '', regex=True)
    metadata['position'] = metadata['position'].str.replace(r"[\[\]']", '', regex=True)

    merged_data = pd.merge(hits, metadata, on='cluster', how='left').drop_duplicates()

    merged_data.to_csv(hit_data, sep="\t", index=False)

    print(f'Metadata saved to {hit_data}')


def filter_fasta(orf_fasta, hit_data, out_fasta):
    """
    Subsets ORFs in FASTA format based on Tra hits and writes the filtered sequences to an output FASTA file.

    Args:
        orf_fasta (str): Path to the input FASTA file containing ORFs.
        hit_data (str): Path to the CSV file containing Tra hit data with 'query' and 'cluster' columns.
        out_fasta (str): Path to the output FASTA file where filtered sequences will be written.

    Returns:
        None
    """

    sequences = []
    seq = None
    name = ''
    filtered = []
    hits = pd.read_csv(hit_data, sep='\t')

    tra_ids = hits['query'].tolist()

    with open(orf_fasta, 'r') as file:
        for line in file:
            line = line.strip()
            if line.startswith('>'):
                if seq is not None:
                    sequences.append((name, seq))
                name = line[1:]
                seq = ''
            else:
                seq += line
        if seq is not None:
            sequences.append((name, seq))

    for name, seq in sequences:
        if name in tra_ids:
            tra_row = hits[hits['query'] == name]
            tra_id = tra_row.loc[:, 'cluster'].values
            formatted_tra_id = ', '.join(tra_id)
            filtered.append((f'{formatted_tra_id} {name}', seq))

    with open(out_fasta, 'w') as file:
        for name, sequence in filtered:
            file.write(f'>{name}\n{sequence}\n')

    print(f'Filtered sequences saved to {out_fasta}')


def run_mmseqs_aa(amino_acids_db, tra_db_dir, tra_amino_acids, tra_amino_data, basename, outdir, num_proc, mai, mac, mae):
    """
    Run MMseqs2 to search for amino acid sequences in a database and process the results.
    
    Args:
        amino_acids_db (str): Path to the amino acids database.
        tra_db_dir (str): Directory for the TraDB database.
        tra_amino_acids (str): Path to the TraDB amino acids file.
        tra_amino_data (str): Path to the TraDB metadata file.
        basename (str): Base name for output files.
        outdir (str): Output directory for results.
        num_proc (int): Number of processors to use for MMseqs2.
        mai (float): Minimum alignment identity for filtering hits.
        mac (float): Minimum alignment coverage for filtering hits.
        mae (float): Maximum e-value for filtering hits.
    
    Returns:
        None
    """

    raw_aa_hits = f'{outdir}/{basename}_aa_raw_hits.tsv'
    filtered_aa_hits = f'{outdir}/{basename}_aa_filtered_hits.tsv'
    hit_aa_data = f'{outdir}/{basename}_aa_hit_data.tsv'

    orf_aa_fasta = f'{outdir}/{basename}_aa.fa'
    out_aa_fasta = f'{outdir}/{basename}_aa_hit_sequences.fa'

    if not os.path.exists(tra_db_dir):
        os.makedirs(tra_db_dir)
    if not os.path.exists(amino_acids_db):
        wget_fa_cmd = f'wget https://github.com/DEpt-metagenom/TraDb/raw/main/tra_db/Tra_db_sequences_aa.fa.gz -O {tra_amino_acids}.gz && gunzip {tra_amino_acids}.gz'
        create_mmseqs_db_cmd = f'mmseqs createdb {tra_amino_acids} {amino_acids_db} && mmseqs createindex {amino_acids_db} {tra_db_dir}/tmp'
        wget_metadb_cmd = f'wget https://github.com/DEpt-metagenom/TraDb/raw/main/tra_db/Tra_db_taxa_positons_aa.db -O {tra_amino_data}'
        os.system(wget_fa_cmd)
        os.system(create_mmseqs_db_cmd)
        os.system(wget_metadb_cmd)

    mmseqs_cmd = f'mmseqs easy-search --threads {num_proc} --format-mode 4 \
        --format-output \"target,query,pident,nident,qcov,evalue,gapopen,tlen,qlen,bits\" \
        --cov-mode 2 -c 0.8 --min-seq-id 0.8 -e 1e-50 {outdir}/{basename}_aa.fa {amino_acids_db} {raw_aa_hits} tmp 1> {outdir}/{basename}_aa_mmseqs.log'
    
    os.system(mmseqs_cmd)

    with open(raw_aa_hits, 'r') as fp:
        bp_raw_lines = sum(1 for line in fp if not line.startswith('target'))

    if bp_raw_lines == 0:
        print("No MMseqs2 hits could be found using AA sequences.")
        exit()

    filter_hits(raw_aa_hits, filtered_aa_hits, mai, mac, mae)

    with open(filtered_aa_hits, 'r') as fp:
        bp_filt_lines = sum(1 for line in fp if not line.startswith('target'))

    if bp_filt_lines == 0:
        print("Filtering removed all hits. Check the table of raw hits and try running again with updated criteria.")
        exit()

    get_metadata(filtered_aa_hits, tra_amino_data, hit_aa_data)

    filter_fasta(orf_aa_fasta, hit_aa_data, out_aa_fasta)


def run_mmseqs_dna(dna_db, tra_db_dir, tra_dna, tra_dna_data, basename, outdir, num_proc, mdi, mdc, mde):
    """
    Runs MMseqs2 to search for DNA sequences in a given database and processes the results.
    
    Args:
        dna_db (str): Path to the DNA database.
        tra_db_dir (str): Directory for the TraDB database.
        tra_dna (str): Path to the TraDB DNA sequences file.
        tra_dna_data (str): Path to the TraDB metadata file.
        basename (str): Basename for output files.
        outdir (str): Output directory for results.
        num_proc (int): Number of processor threads to use.
        mdi (float): Minimum sequence identity for filtering hits.
        mdc (float): Minimum coverage for filtering hits.
        mde (float): Maximum e-value for filtering hits.
    
    Returns:
        None
    """
    
    raw_dna_hits = f'{outdir}/{basename}_dna_raw_hits.tsv'
    filtered_dna_hits = f'{outdir}/{basename}_dna_filtered_hits.tsv'
    hit_dna_data = f'{outdir}/{basename}_dna_hit_data.tsv'

    orf_dna_fasta = f'{outdir}/{basename}_dna.fa'
    out_dna_fasta = f'{outdir}/{basename}_dna_hit_sequences.fa'

    if not os.path.exists(tra_db_dir):
        os.makedirs(tra_db_dir)
    if not os.path.exists(dna_db):
        wget_fa_cmd = f'wget https://github.com/DEpt-metagenom/TraDb/raw/main/tra_db/Tra_db_sequences_aa.fa.gz -O {tra_dna}.gz && gunzip {tra_dna}.gz'
        create_mmseqs_db_cmd = f'mmseqs createdb {tra_dna} {dna_db} && mmseqs createindex {dna_db} {tra_db_dir}/tmp'
        wget_metadb_cmd = f'wget https://github.com/DEpt-metagenom/TraDb/raw/main/tra_db/Tra_db_taxa_positons_aa.db -O {tra_dna_data}'
        os.system(wget_fa_cmd)
        os.system(create_mmseqs_db_cmd)
        os.system(wget_metadb_cmd)

    mmseqs_cmd = f'mmseqs easy-search --threads {num_proc} --format-mode 4 \
        --format-output \"target,query,pident,nident,qcov,evalue,gapopen,tlen,qlen,bits\" \
        --cov-mode 2 -c 0.8 --min-seq-id 0.8 -e 1e-50 {outdir}/{basename}_dna.fa {dna_db} {raw_dna_hits} tmp 1> {outdir}/{basename}_dna_mmseqs.log'
    
    os.system(mmseqs_cmd)

    with open(raw_dna_hits, 'r') as fp:
        bp_raw_lines = sum(1 for line in fp if not line.startswith('target'))

    if bp_raw_lines == 0:
        print("No MMseqs2 hits could be found using DNA sequences.")
        exit()

    filter_hits(raw_dna_hits, filtered_dna_hits, mdi, mdc, mde)

    with open(filtered_dna_hits, 'r') as fp:
        bp_filt_lines = sum(1 for line in fp if not line.startswith('target'))

    if bp_filt_lines == 0:
        print("Filtering removed all hits. Check the table of raw hits and try running again with updated criteria.")
        exit()

    get_metadata(filtered_dna_hits, tra_dna_data, hit_dna_data)

    filter_fasta(orf_dna_fasta, hit_dna_data, out_dna_fasta)


def main():
    """
    Main function that parses command-line arguments and runs the pipeline for screening conjugation transfer genes in plasmid sequences.

    The function performs the following steps:
    1. Parses command-line arguments.
    2. Checks for required dependencies.
    3. Creates the output directory if it does not exist.
    4. Runs the appropriate pipeline based on the input arguments.

    Command-line Arguments:
    - input_fasta (str): Input fasta file. Mandatory input.
    - --type, -t (str): Type of search to be run. Choices are 'dna', 'aa', 'both'. Default is 'both'.
    - --reading_frames, -ORF (bool): If the input consists of ORFs. Default is False.
    - --plasmid_prediction, -p (bool): If plasmid prediction of the input should be attempted. Default is False.
    - --number_of_processors, -np (int): Number of processes invoked for the search. Default is 1.
    - --output_directory, -o (str): Output directory to store results. Default is "tra_out".
    - --platon_db_dir, -pdb (str): Directory where the reference database of platon can be found. Default is $HOME/platon_db.
    - --transfer_gene_db_dir, -tdb (str): Directory where the reference conjugational transfer gene database can be found. Default is $HOME/tra_db.
    - --min_aa_identity, -mai (str): Minimum percent of identity when screening amino acids. Default is 80.
    - --min_aa_coverage, -mac (str): Minimum percent of coverage when screening amino acids. Default is 0.8.
    - --min_aa_evalue, -mae (str): Minimum e-value when screening amino acids. Default is 1e-50.
    - --min_dna_identity, -mdi (str): Minimum percent of identity when screening DNA sequences. Default is 80.
    - --min_dna_coverage, -mdc (str): Minimum percent of coverage when screening DNA sequences. Default is 0.8.
    - --min_dna_evalue, -mde (str): Minimum e-value when screening DNA sequences. Default is 1e-50.
    - --version, -V: Print version number and exit.

    The function also includes basic logging to print the status of the run and checks for the availability of required dependencies.
    """

    print("""
                                          _____          ____  _
           ___  ___ _ __ ___  ___ _ __   |_   _| __ __ _|  _ \| |__
          / __|/ __| '__/ _ \/ _ \ '_ \    | || '__/ _` | | | | '_ \\
          \__ \ (__| | |  __/  __/ | | |   | || | | (_| | |_| | |_) |
          |___/\___|_|  \___|\___|_| |_|   |_||_|  \__,_|____/|_.__/ v0.2
    """)

    # parse arguments
    parser = argparse.ArgumentParser(description="Screening of conjugation transfer genes in plasmid sequences.")
    parser.add_argument("input_fasta", help="Input fasta file. Mandatory input.")
    parser.add_argument("--type", "-t", default='both', choices=['dna', 'aa', 'both'], help="Type of search to be run.")
    parser.add_argument("--reading_frames", "-ORF", default='False', action='store_true', help="If the input consits of ORFs. Use this only if you alredy predicted the ORFs of the input. If set, you should also consider to change --type appropriately. Default is False.")
    parser.add_argument("--plasmid_prediction", "-p", default='False', action='store_true', help="If plasmid prediction of the input should be attempted. The output of platon containing the plasmids will be screened for transfer genes")
    parser.add_argument("--number_of_processors", "-np", type=int, default='1', help="Number of processes invoked for the search.")
    parser.add_argument("--output_directory", "-o", default="tra_out", help="Output directory to store results. Output files will be named using the basename of the input file.")
    parser.add_argument("--platon_db_dir", "-pdb", default=f"{home_dir}/platon_db", help="Where the reference database of platon can be found. Default is $HOME/platon_db. If it can not be found automatic install will be attempted.")
    parser.add_argument("--transfer_gene_db_dir", "-tdb", default=f"{home_dir}/tra_db", help="Where the reference conjugational transfer gene database can be found. Default is $HOME/tra_db. If it can not be found automatic install will be attempted.")
    parser.add_argument("--min_aa_identity", "-mai", default='80', help="Minimum percent of identity when screening amino acids (0-100). Default is 80.")
    parser.add_argument("--min_aa_coverage", "-mac", default='0.8', help="Minimum percent of identity when screening amino acids (0-100). Default is 80.")
    parser.add_argument("--min_aa_evalue", "-mae", default='1e-50', help="Minimum e-value when screening amino acids. Default is 1e-50.")
    parser.add_argument("--min_dna_identity", "-mdi", default='80', help="Minimum percent of identity when screening DNA sequences (0-100). Default is 80.")
    parser.add_argument("--min_dna_coverage", "-mdc", default='0.8', help="Minimum percent of identity when screening DNA sequences (0-100). Default is 80.")
    parser.add_argument("--min_dna_evalue", "-mde", default='1e-50', help="Minimum e-value when screening DNA sequences. Default is 1e-50.")
    parser.add_argument("--version", "-V", action='version', version=version_number, help="Print version number and exit")
    args = parser.parse_args()

    infile = args.input_fasta
    run_type = args.type
    basename = os.path.splitext(os.path.basename(infile))[0]
    outdir = args.output_directory
    input_orf = args.reading_frames
    plasmid_predict = args.plasmid_prediction
    num_proc = args.number_of_processors
    platon_db_dir = args.platon_db_dir
    tra_db_dir = args.transfer_gene_db_dir
    amino_acids_db = f'{tra_db_dir}/Tra_db_sequences_aa'
    tra_amino_acids = f'{amino_acids_db}.fa'
    tra_amino_data = f'{tra_db_dir}/Tra_db_taxa_positons_aa.db'
    mai = args.min_aa_identity
    mac = args.min_aa_coverage
    mae = args.min_aa_evalue
    dna_db = f'{tra_db_dir}/Tra_db_sequences_dna'
    tra_dna = f'{dna_db}.fa'
    tra_dna_data = f'{tra_db_dir}/Tra_db_taxa_positons_dna.db'
    mdi = args.min_dna_identity
    mdc = args.min_dna_coverage
    mde = args.min_dna_evalue

    # TODO improve logging
    print(f'Reading input file: {args.input_fasta}')
    print(f'Type of search is set to: {args.type}')
    #print(args.reading_frames)
    #print(args.plasmid_prediction)
    print(f'The run will use {args.number_of_processors} threads')
    print(f'Output will be saved to {args.output_directory}')
    #print(args.platon_db_dir)

    dependencies = ['prodigal', 'bedtools', 'platon', 'wget', 'mmseqs']

    for dep in dependencies:
        is_tool = os.system(f'which {dep}')
        if is_tool > 0:
            print(f'{dep} is not available')
            exit()

    if input_orf != "False":
        if plasmid_predict == input_orf:
            print("--reading_frames and --plasmid_prediction are both set \"True\". Check your input and run screen_tradb again.")
            exit()

    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # logic
    if input_orf == "False" and plasmid_predict == "False":
        run_prodigal(infile, basename, outdir)
        if run_type == "both":
            run_mmseqs_dna(dna_db, tra_db_dir, tra_dna, tra_dna_data, basename, outdir, num_proc, mdi, mdc, mde)
            run_mmseqs_aa(amino_acids_db, tra_db_dir, tra_amino_acids, tra_amino_data, basename, outdir, num_proc, mai, mac, mae)
        if run_type == "dna":
            run_mmseqs_dna(dna_db, tra_db_dir, tra_dna, tra_dna_data, basename, outdir, num_proc, mdi, mdc, mde)
        if run_type == "aa":
            run_mmseqs_aa(amino_acids_db, tra_db_dir, tra_amino_acids, tra_amino_data, basename, outdir, num_proc, mai, mac, mae)

    elif input_orf != "False" and plasmid_predict == "False":
        if run_type == "dna":
            cp_cmd = f'cp {infile} {outdir}/{basename}_dna.fa'
            os.system(cp_cmd)
            run_mmseqs_dna(dna_db, tra_db_dir, tra_dna, tra_dna_data, basename, outdir, num_proc, mdi, mdc, mde)
        if run_type == "aa":
            cp_cmd = f'cp {infile} {outdir}/{basename}_aa.fa'
            os.system(cp_cmd)
            run_mmseqs_aa(amino_acids_db, tra_db_dir, tra_amino_acids, tra_amino_data, basename, outdir, num_proc, mai, mac, mae)

    elif input_orf == "False" and plasmid_predict != "False":
        run_platon(infile, basename, outdir, num_proc, platon_db_dir)
        prodigal_infile = f'{basename}_platon/{basename}.plasmid.fasta'
        run_prodigal(prodigal_infile, basename, outdir)
        if run_type == "both":
            run_mmseqs_dna(dna_db, tra_db_dir, tra_dna, tra_dna_data, basename, outdir, num_proc, mdi, mdc, mde)
            run_mmseqs_aa(amino_acids_db, tra_db_dir, tra_amino_acids, tra_amino_data, basename, outdir, num_proc, mai, mac, mae)
        if run_type == "dna":
            run_mmseqs_dna(dna_db, tra_db_dir, tra_dna, tra_dna_data, basename, outdir, num_proc, mdi, mdc, mde)
        if run_type == "aa":
            run_mmseqs_aa(amino_acids_db, tra_db_dir, tra_amino_acids, tra_amino_data, basename, outdir, num_proc, mai, mac, mae)

if __name__ == "__main__":
    main()
